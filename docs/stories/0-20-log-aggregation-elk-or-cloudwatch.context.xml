<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>0</epicId>
    <storyId>20</storyId>
    <title>Log Aggregation (ELK or CloudWatch)</title>
    <status>drafted</status>
    <generatedAt>2026-01-24</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/0-20-log-aggregation-elk-or-cloudwatch.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>Developer</asA>
    <iWant>centralized log aggregation</iWant>
    <soThat>I can debug issues across distributed services</soThat>
    <tasks>
      <task id="1" name="CloudWatch Log Groups Setup" acs="1,7">
        <subtask>1.1 Create CloudWatch log group: /qualisys/staging/api</subtask>
        <subtask>1.2 Create CloudWatch log group: /qualisys/staging/worker</subtask>
        <subtask>1.3 Create CloudWatch log group: /qualisys/production/api</subtask>
        <subtask>1.4 Create CloudWatch log group: /qualisys/production/worker</subtask>
        <subtask>1.5 Configure retention: 30 days staging, 90 days production</subtask>
        <subtask>1.6 Set up log group encryption (KMS key)</subtask>
      </task>
      <task id="2" name="Fluent Bit DaemonSet Deployment" acs="2,3,4">
        <subtask>2.1 Deploy Fluent Bit as DaemonSet in monitoring namespace</subtask>
        <subtask>2.2 Configure Fluent Bit to collect container logs</subtask>
        <subtask>2.3 Configure Fluent Bit to ship to CloudWatch Logs</subtask>
        <subtask>2.4 Set up IRSA (IAM Role for Service Account) for Fluent Bit</subtask>
        <subtask>2.5 Configure multiline log parsing for stack traces</subtask>
        <subtask>2.6 Verify logs appearing in CloudWatch</subtask>
      </task>
      <task id="3" name="Structured Logging Implementation" acs="5,6,12">
        <subtask>3.1 Implement JSON logger utility (Winston/Pino)</subtask>
        <subtask>3.2 Add required fields: timestamp, level, message</subtask>
        <subtask>3.3 Add trace_id correlation (from X-Request-ID header)</subtask>
        <subtask>3.4 Add tenant_id context to all log entries</subtask>
        <subtask>3.5 Create logging middleware for HTTP requests</subtask>
        <subtask>3.6 Document logging standards and usage</subtask>
      </task>
      <task id="4" name="PII Redaction" acs="11">
        <subtask>4.1 Create PII redaction filter for Fluent Bit</subtask>
        <subtask>4.2 Configure email masking (user@***.com)</subtask>
        <subtask>4.3 Configure name masking (John D***)</subtask>
        <subtask>4.4 Test redaction with sample PII data</subtask>
        <subtask>4.5 Document PII handling in logs</subtask>
      </task>
      <task id="5" name="Log-Based Alerts" acs="9,10">
        <subtask>5.1 Create CloudWatch Metric Filter for error count</subtask>
        <subtask>5.2 Create CloudWatch Alarm for greater than 10 errors/min</subtask>
        <subtask>5.3 Create CloudWatch Metric Filter for 5xx responses</subtask>
        <subtask>5.4 Create CloudWatch Alarm for 5xx rate greater than 5%</subtask>
        <subtask>5.5 Configure alarm notifications to SNS topic</subtask>
        <subtask>5.6 Connect SNS to Slack webhook</subtask>
      </task>
      <task id="6" name="Access and Documentation" acs="8">
        <subtask>6.1 Configure IAM policy for log access</subtask>
        <subtask>6.2 Create CloudWatch Logs Insights saved queries</subtask>
        <subtask>6.3 Document common log search patterns</subtask>
        <subtask>6.4 Create runbook for log investigation</subtask>
        <subtask>6.5 Verify team members can access logs</subtask>
      </task>
    </tasks>
  </story>

  <acceptanceCriteria>
    <criterion id="AC1">Log aggregation system deployed (CloudWatch Logs)</criterion>
    <criterion id="AC2">API logs shipped to central system (request/response, errors)</criterion>
    <criterion id="AC3">Worker logs shipped (background jobs, AI agent pipeline)</criterion>
    <criterion id="AC4">Kubernetes system logs collected (kubelet, kube-proxy)</criterion>
    <criterion id="AC5">Logs structured in JSON format</criterion>
    <criterion id="AC6">Logs include required fields: timestamp, level, message, trace_id, tenant_id</criterion>
    <criterion id="AC7">Log retention: 30 days staging, 90 days production</criterion>
    <criterion id="AC8">Log search interface accessible at CloudWatch Console</criterion>
    <criterion id="AC9">Log-based alert: Error rate spike (greater than 10 errors/min)</criterion>
    <criterion id="AC10">Log-based alert: 5xx response rate greater than 5%</criterion>
    <criterion id="AC11">PII redaction enabled (email, names masked in logs)</criterion>
    <criterion id="AC12">Cross-service trace correlation via trace_id</criterion>
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/tech-specs/tech-spec-epic-0.md</path>
        <title>Epic 0 Technical Specification</title>
        <section>Observability Requirements</section>
        <snippet>NFR-OBS1: Centralized logging with PII redaction. NFR-OBS2: Correlation IDs for distributed tracing.</snippet>
      </doc>
      <doc>
        <path>docs/epics/epic-0-infrastructure.md</path>
        <title>Epic 0: Infrastructure Foundation</title>
        <section>Story 0.20: Log Aggregation</section>
        <snippet>CloudWatch Logs for centralized logging with Fluent Bit as log shipper.</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>System Architecture</title>
        <section>Logging Strategy</section>
        <snippet>Structured JSON logs with trace_id and tenant_id for distributed debugging.</snippet>
      </doc>
    </docs>
    <code>
      <file>
        <path>docs/stories/0-3-kubernetes-cluster-provisioning.md</path>
        <kind>story</kind>
        <symbol>Kubernetes Cluster</symbol>
        <reason>Dependency: Monitoring namespace for Fluent Bit DaemonSet</reason>
      </file>
      <file>
        <path>docs/stories/0-1-cloud-account-iam-setup.md</path>
        <kind>story</kind>
        <symbol>IAM Setup</symbol>
        <reason>Dependency: IAM role for Fluent Bit CloudWatch access</reason>
      </file>
      <file>
        <path>docs/stories/0-7-secret-management.md</path>
        <kind>story</kind>
        <symbol>Secret Management</symbol>
        <reason>Optional: Slack webhook URL for alert notifications</reason>
      </file>
    </code>
    <dependencies>
      <terraform>
        <module name="aws_cloudwatch_log_group">CloudWatch log group resources</module>
        <module name="aws_cloudwatch_metric_filter">Metric filters for alerts</module>
        <module name="aws_cloudwatch_metric_alarm">CloudWatch alarms</module>
      </terraform>
      <node>
        <package name="pino" version="^8.16.0">Fast JSON logger</package>
        <package name="pino-pretty" version="^10.2.0">Pretty print for development</package>
        <package name="uuid" version="^9.0.0">UUID for trace ID generation</package>
      </node>
      <kubernetes>
        <image name="amazon/aws-for-fluent-bit" version="2.31.12">Fluent Bit for AWS</image>
      </kubernetes>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint type="tool">AWS CloudWatch Logs (managed, simpler than ELK for MVP)</constraint>
    <constraint type="shipper">Fluent Bit (lightweight, Kubernetes-native)</constraint>
    <constraint type="retention">30 days staging, 90 days production</constraint>
    <constraint type="format">JSON structured logs with standard fields</constraint>
    <constraint type="privacy">PII must be redacted before shipping to logs</constraint>
  </constraints>

  <interfaces>
    <interface>
      <name>Logger</name>
      <kind>class</kind>
      <signature>class Logger { debug, info, warn, error, setTraceId, setTenantId }</signature>
      <path>src/logger/index.ts</path>
    </interface>
    <interface>
      <name>loggingMiddleware</name>
      <kind>function</kind>
      <signature>loggingMiddleware(req, res, next): void</signature>
      <path>src/logger/index.ts</path>
    </interface>
    <interface>
      <name>CloudWatch Logs Insights</name>
      <kind>query interface</kind>
      <signature>fields @timestamp, @message | filter level = "error"</signature>
      <path>AWS Console</path>
    </interface>
  </interfaces>

  <tests>
    <standards>
      Infrastructure validation through CloudWatch Console. Verify log groups exist, logs appear with correct
      structure, PII is redacted, and alerts fire on threshold breach. Use AWS CLI for automation.
    </standards>
    <locations>
      <location>terraform/modules/logging/</location>
      <location>k8s/logging/</location>
      <location>src/logger/</location>
    </locations>
    <ideas>
      <idea ac="AC1">Verify CloudWatch log groups exist via AWS CLI</idea>
      <idea ac="AC2,3,4">Query logs and verify entries from API, worker, K8s</idea>
      <idea ac="AC5,6">Parse sample log entry as JSON, verify required fields</idea>
      <idea ac="AC7">Verify retention policy settings in CloudWatch Console</idea>
      <idea ac="AC8">Team member accesses logs via CloudWatch Console</idea>
      <idea ac="AC9">Generate 15 errors in 1 minute, verify alarm fires</idea>
      <idea ac="AC10">Generate 10% 5xx responses, verify alarm fires</idea>
      <idea ac="AC11">Search for PII pattern, verify masked values</idea>
      <idea ac="AC12">Filter by trace_id, verify related logs across services</idea>
    </ideas>
  </tests>
</story-context>
